{
    "recipe_id": "llm_inference_amd",
    "recipe_mode": "service",
    "deployment_name": "gpt-oss-tp8",
    "recipe_image_uri": "rocm/vllm-dev:open-mi300-08052025",
    "recipe_node_shape": "BM.GPU.MI300X.8",
    "recipe_replica_count": 1,
    "recipe_container_port": "8000",
    "recipe_amd_gpu_count": 8,
    "recipe_ephemeral_storage_size": 400,
    "recipe_shared_memory_volume_size_limit_in_mb": 32768,
    "recipe_use_shared_node_pool": true,
    "recipe_prometheus_enabled": true,
    "local_filesystem": [
        {
            "mount_location": "/models",
            "node_directory_path": "/mnt/nvme/models"
        }
    ],
    "recipe_container_env": [
        {
            "key": "VLLM_USE_AITER_UNIFIED_ATTENTION",
            "value": "1"
        },
        {
            "key": "VLLM_ROCM_USE_AITER_MHA",
            "value": "0"
        },
        {
            "key": "VLLM_ROCM_USE_AITER",
            "value": "1"
        }
    ],
    "recipe_container_command_args": [
        "vllm",
        "serve",
        "/models/openai/gpt-oss-120b",
        "--tensor-parallel",
        "8",
        "--no-enable-prefix-caching",
        "--disable-log-requests",
        "--compilation-config",
        "{\"full_cuda_graph\": true}",
        "--served-model-name",
        "openai/gpt-oss-120"
    ],
    "recipe_readiness_probe_params": {
        "endpoint_path": "/health",
        "port": 8000,
        "scheme": "HTTP",
        "initial_delay_seconds": 20,
        "period_seconds": 30,
        "success_threshold": 1,
        "timeout_seconds": 10
    },
    "recipe_liveness_probe_params": {
        "failure_threshold": 3,
        "endpoint_path": "/health",
        "port": 8000,
        "scheme": "HTTP",
        "initial_delay_seconds": 1200,
        "period_seconds": 60,
        "success_threshold": 1,
        "timeout_seconds": 10
    }
}