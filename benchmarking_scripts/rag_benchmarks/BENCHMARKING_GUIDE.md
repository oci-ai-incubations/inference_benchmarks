# NVIDIA RAG Blueprint Benchmarking Guide

## Here's how to use it effectively with your NVIDIA RAG Blueprint.

## ğŸ“Š **What Tests were done**

âœ… **Successfully ran a quick benchmark** with the following results:
- **Average Latency**: ~115ms
- **P95 Latency**: ~125ms  
- **Throughput**: ~4.6 RPS
- **Success Rate**: 100%
- **Generated**: JSON reports, PNG visualizations, and summary data

##  **Quick Start Commands**

### **1. Run a Quick Test (Recommended for first-time users)**
```bash
./benchmark/run_benchmark_with_env.sh --preset quick
```

### **2. Run Standard Performance Test**
```bash
./benchmark/run_benchmark_with_env.sh --preset standard
```

### **3. Run Stress Test (High Load)**
```bash
./benchmark/run_benchmark_with_env.sh --preset stress
```

### **4. Run Accuracy Evaluation**
```bash
cd benchmark
source ../.venv/bin/activate
python accuracy_evaluator.py
```

### **5. Run All Examples**
```bash
cd benchmark
source ../.venv/bin/activate
python example_usage.py
```

## ğŸ“ˆ **Understanding The Results**

### **Performance Metrics Explained:**

| Metric | What It Means | Results Achieved |
|--------|---------------|--------------|
| **Average Latency** | Time for a typical request | ~115ms |
| **P95 Latency** | 95% of requests faster than this | ~125ms |
| **Throughput** | Requests per second | ~4.6 RPS |
| **Success Rate** | Percentage of successful requests | 100% |

### **What the Results Tell You:**

1. **Latency is Good**: 115ms average is excellent for RAG systems
2. **Consistency is High**: P95 latency close to average shows stable performance
3. **Reliability is Perfect**: 100% success rate indicates robust system
4. **Throughput is Reasonable**: 4.6 RPS is good for a single-instance setup

## ğŸ”§ **Available Benchmark Types**

### **Preset Configurations:**

| Preset | Requests | Concurrent | Use Case |
|--------|----------|------------|----------|
| `quick` | 20 | 3 | Development testing  |
| `standard` | 100 | 10 | General evaluation |
| `stress` | 500 | 20 | Load testing |
| `accuracy` | 50 | 5 | Quality assessment |
| `performance` | 200 | 15 | Performance optimization |

### **Benchmark Types:**

1. **Concurrent Benchmark**: Tests system under load
2. **Latency Benchmark**: Measures response times for different query types
3. **Accuracy Benchmark**: Evaluates response quality (requires ground truth)

## ğŸ“ **Output  Generated**

After running a benchmark, you'll find:

```
benchmark/benchmark_results/
â”œâ”€â”€ quick/                          # Results directory
â”‚   â”œâ”€â”€ benchmark_*.json           # Detailed metrics
â”‚   â”œâ”€â”€ benchmark_plots_*.png      # Visualization charts
â”‚   â””â”€â”€ benchmark_summary_*.json   # Summary report
```

### **Key Files:**
- **`benchmark_summary_*.json`**: High-level results comparison
- **`benchmark_plots_*.png`**: Latency distribution and performance charts
- **`benchmark_*_benchmark_*.json`**: Detailed metrics for each test type

##  **Next Steps To Do For Optimization**

### **1. Baseline Your Current Performance**
```bash
# Run standard benchmark to establish baseline
./benchmark/run_benchmark_with_env.sh --preset standard
```

### **2. Test Different Configurations**
```bash
# Compare with and without reranker
./benchmark/run_benchmark_with_env.sh --preset performance
./benchmark/run_benchmark_with_env.sh --preset accuracy
```

### **3. Monitor Resource Usage**
The benchmark automatically tracks:
- CPU utilization
- Memory usage
- Token processing rates
- Error rates



### **Performance Tuning:**

```bash
# For lower latency, try:
./benchmark/run_benchmark_with_env.sh --preset performance

# For higher accuracy, try:
./benchmark/run_benchmark_with_env.sh --preset accuracy
```

## **Interpreting The Results**

### **Good Performance Indicators:**
- âœ… Average latency < 200ms
- âœ… P95 latency < 2x average latency
- âœ… Success rate > 95%
- âœ… Consistent throughput

### **Areas for Improvement:**
- âš ï¸ Average latency > 500ms
- âš ï¸ P95 latency > 3x average latency
- âš ï¸ Success rate < 90%
- âš ï¸ Inconsistent throughput

##  **Advanced Usage**

### **Custom Configuration:**
```bash
# Save current configuration
./benchmark/run_benchmark_with_env.sh --preset standard --save-config my_config.json

# Run with custom config
./benchmark/run_benchmark_with_env.sh --config my_config.json
```

### **Continuous Monitoring:**
```bash
# Run benchmarks regularly
# Add to cron job for continuous monitoring
0 */6 * * * cd /home/ubuntu/rag && ./benchmark/run_benchmark_with_env.sh --preset quick
```

##  **Success Metrics**

Our current setup shows **good performance**:

- **Latency**: 115ms average (excellent for RAG)
- **Reliability**: 100% success rate
- **Consistency**: P95 close to average
- **Throughput**: 4.6 RPS (good for single instance)
